Clustering and Failover

If High Availability is required, an application can be clustered with miner changes in configuration and deployment.

Clustering allows multiple instances of an application to run in parallel across a set of servers (a.k.a cluster nodes) while providing a single view to application clients. Load is distributed across different the servers and across the different services executing within those servers.  Load distribution (i.e. load balancing) is carried out by Routers.  If one or more of the servers fails, the application is still accessible via the surviving nodes.

Clustering is important for an application to be scalable, one can improve performance by simply adding more nodes to the cluster. Clustering is central to highly available applications - the clustering infrastructure supports the redundancy needed for high availability. 

Distributing requests between nodes

A load-balancer is a single entry-point to all nodes where an application is running.  All calls should be made through the load balancer.


We provide two solutions, one based on SIP, and the other based on our simple standalone session management protocol.  Load balancing can be customized to allow application-specific logic to drive the balancer.  Custom, application-specific load balancing is done using individual router plugins which can be applied either on service by service basis or appliaed wide-application.


Service Architectures

The clustering topography defined for an application dictates which nodes are included and which services are running.

From the developer's perspective, we are concerned about the cluster architecture from a client application's point of view.  Two basic clustering architectures are available: client-side interceptors (a.k.a smart proxies or stubs) and external load balancers.  Which architecture your application will use will depend on how you wish to have clients access the services.

Different types of service access are available. Service access in general is either one-way or two-way, and, can be synchronous or asynchronous. Synchronous access (request/response) is done via service invocation.  Asynchronous service access is carried out with messagee sending.

Application services executing in servers distributed across the cluster can be accessed in two ways, one way HTTP-based, the other way non-HTTP-based.  Accessing services via HTTP is done through standard web-service invocation. Accessing services in non-HTTP ways include JNDI, EJB, JMS, RMI 


Client-side interceptor architecture

, including JNDI, EJB, JMS, RMI and JBoss Remoting, require the client to obtain (e.g., to look up and download) a stub (or proxy) object. The stub object is generated by the server and it implements the business interface of the service. The client then makes local method calls against the stub object. The stub automatically routes the call across the network and where it is invoked against service objects managed in the server. In a clustered environment, the server-generated stub object will include an interceptor that understands how to distribute calls among the multiple nodes in the cluster. The stub object figures out how to find the appropriate server node, marshal call parameters, un-marshall call results, and return the result to the caller client.

The stub interceptors maintain up-to-date knowledge about the cluster. For instance, they know the IP addresses of all available server nodes, the algorithm to distribute load across nodes (see next section), and how to failover the request if the target node not available. As part of handling each service request, if the cluster topology has changed the server node updates the stub interceptor with the latest changes in the cluster. For instance, if a node drops out of the cluster, each of client stub interceptor is updated with the new configuration the next time it connects to any active node in the cluster. All the manipulations done by the service stub are transparent to the client application. The client-side interceptor clustering architecture is illustrated in Figure 1.2, The client-side interceptor (proxy) architecture for clustering. 


Testing


Session Initiation Protocol (SIP) is a communications protocol used to create, modify, and terminate sessions with one or more users.

A typical SIP session involves a client requesting a session with a SIP server. After the request is received, the SIP server returns a response to the user indicating the availability of the session. SIP is ASCII text-based and it shares some common characteristics with HTTP. Users are identified by a SIP address which is similar to an email address.

SIP relies on a peer to peer architecture that uses intelligent network elements for advanced call processing and call management functions. These endpoints are referred to as the user agent client and the user agent server. A proxy server can be used as an intermediary responsible for transferring the request from the client to the SIP server. SIP proxy servers can provide advanced call processing functions including security, authentication, and call routing.
